{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a87ea259-5f33-4850-bbb8-a1cc135dad82",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7556b2db-0b0b-4a60-8d12-55ae87bcf0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import MSELoss\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf16ada-b35c-4970-9f6c-8ed24d2ac36a",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e82d7b7b-0bdb-4db9-b8f2-aa86b1c68488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv('battery_feature_extracted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc27e09b-51a6-45e7-a04d-a680bd1d8de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target\n",
    "X = dataset.drop(columns=['average_voltage'])\n",
    "y = dataset['average_voltage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3eb5919-01b4-4a4f-964e-b973654006f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split to separate out the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afc3c3f9-31af-495d-b062-f16d14f64b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second split: separate the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)  # 20% for validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c0a4653-44f3-4aca-8e0b-1ff40539b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the features (fit on X_train, apply to all)\n",
    "scaler = RobustScaler()\n",
    "#scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5b7cb63-3a37-4eb7-9ed1-5b945c419148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values).unsqueeze(1)  # Ensure target tensor is of the right shape\n",
    "X_val_tensor = torch.FloatTensor(X_val_scaled)\n",
    "y_val_tensor = torch.FloatTensor(y_val.values).unsqueeze(1)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17449a1c-d0d6-498d-b9da-c1289e214993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "num_features = X_train_scaled.shape[1]\n",
    "output_size = 1  # For regression, we predict a single continuous value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef707475-69e3-4607-863d-4e763e3e4074",
   "metadata": {},
   "source": [
    "# Define and Load the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91c519b5-0e8d-4600-ae29-3baeea90dbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the TabTransformer model for regression\n",
    "class TabTransformer(nn.Module):\n",
    "    def __init__(self, num_features, output_size=1, dim_embedding=64, num_heads=4, num_layers=4, dropout=0.1):\n",
    "        super(TabTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(num_features, dim_embedding)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=dim_embedding, nhead=num_heads, batch_first=True, dropout=dropout)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.regressor = nn.Linear(dim_embedding, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # Feature embedding\n",
    "        x = x.unsqueeze(1)  # Add a sequence dimension\n",
    "        x = self.transformer(x)  # Pass through the Transformer encoder\n",
    "        x = torch.mean(x, dim=1)  # Aggregate over the sequence dimension\n",
    "        x = self.regressor(x)  # Predict output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ee799aa-a9ed-4e1b-9032-f4c34559013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c89bc77-4c52-4c66-b452-cf1c6aa8d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss, and optimizer\n",
    "model = TabTransformer(\n",
    "    num_features=num_features,  # Input features\n",
    "    output_size=output_size,    # Output size for regression\n",
    "    dim_embedding=128,          # Embedding dimension\n",
    "    num_heads=2,                # Number of attention heads\n",
    "    num_layers=2,               # Number of transformer layers\n",
    "    dropout=0.2                 # Dropout rate\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "349b5515-98f6-4d45-97a5-136d4dc4687d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25360\\608473013.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('entire_model_transformer_base_mae4447_mse6211_r27630.pth', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained weights\n",
    "model.load_state_dict(torch.load('entire_model_transformer_base_mae4447_mse6211_r27630.pth', map_location=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31e8797e-1b02-403d-9347-a099bcfb139f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabTransformer(\n",
       "  (embedding): Linear(in_features=3226, out_features=128, bias=True)\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (regressor): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af85ca0e-9b9f-4f3b-bc95-59280bfcc338",
   "metadata": {},
   "source": [
    "# Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b8b069f-d840-47c4-8c60-54736b4d2b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.6212\n",
      "Test MAE: 0.4447\n",
      "Test R¬≤:  0.7630\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor.to(device))\n",
    "\n",
    "# Convert predictions and targets to NumPy arrays\n",
    "y_pred = predictions.cpu().numpy().flatten()\n",
    "y_true = y_test_tensor.numpy().flatten()\n",
    "\n",
    "# Compute metrics\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Test MSE: {mse:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")\n",
    "print(f\"Test R¬≤:  {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb57b98-5ae4-4908-bddb-3db5a5470ead",
   "metadata": {},
   "source": [
    "# Bootstrapping + Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76fce370-e715-4ddd-b6e8-c9c446c7ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bootstraps = 1000\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "mse_scores, mae_scores, r2_scores = [], [], []\n",
    "\n",
    "for _ in range(n_bootstraps):\n",
    "    indices = rng.choice(len(y_true), size=len(y_true), replace=True)\n",
    "    y_true_boot = y_true[indices]\n",
    "    y_pred_boot = y_pred[indices]\n",
    "    \n",
    "    mse_scores.append(mean_squared_error(y_true_boot, y_pred_boot))\n",
    "    mae_scores.append(mean_absolute_error(y_true_boot, y_pred_boot))\n",
    "    r2_scores.append(r2_score(y_true_boot, y_pred_boot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "057e2109-b895-419b-a426-880e23b8b64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6172 ¬± 0.1700\n",
      "MAE: 0.4430 ¬± 0.0307\n",
      "R¬≤ : 0.7663 ¬± 0.0410\n"
     ]
    }
   ],
   "source": [
    "print(f\"MSE: {np.mean(mse_scores):.4f} ¬± {np.std(mse_scores):.4f}\")\n",
    "print(f\"MAE: {np.mean(mae_scores):.4f} ¬± {np.std(mae_scores):.4f}\")\n",
    "print(f\"R¬≤ : {np.mean(r2_scores):.4f} ¬± {np.std(r2_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ebad6bd-3cf5-46ec-9b51-94afd638fe0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Bootstrapped Test Metrics (95% Confidence Intervals):\n",
      "MAE: 0.4430 ¬± 0.0307 (95% CI: [0.3869, 0.5083])\n",
      "MSE: 0.6172 ¬± 0.1700 (95% CI: [0.3414, 0.9796])\n",
      "R¬≤: 0.7663 ¬± 0.0410 (95% CI: [0.6799, 0.8434])\n"
     ]
    }
   ],
   "source": [
    "# Convert to NumPy arrays\n",
    "mse_scores = np.array(mse_scores)\n",
    "mae_scores = np.array(mae_scores)\n",
    "r2_scores = np.array(r2_scores)\n",
    "\n",
    "# Compute statistics\n",
    "def summarize(metric_array, name):\n",
    "    mean = np.mean(metric_array)\n",
    "    std = np.std(metric_array)\n",
    "    ci_lower, ci_upper = np.percentile(metric_array, [2.5, 97.5])\n",
    "    print(f\"{name}: {mean:.4f} ¬± {std:.4f} (95% CI: [{ci_lower:.4f}, {ci_upper:.4f}])\")\n",
    "\n",
    "print(\"\\nüîÅ Bootstrapped Test Metrics (95% Confidence Intervals):\")\n",
    "summarize(mae_scores, \"MAE\")\n",
    "summarize(mse_scores, \"MSE\")\n",
    "summarize(r2_scores, \"R¬≤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfa199e-dd47-4bca-9b3c-b283261b85f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
