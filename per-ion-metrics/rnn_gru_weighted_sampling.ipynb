{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9655328-d8af-4e95-b7e7-35c1fcea9d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7fb68e89-3e1e-4ac6-a13a-96f4668aa7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_csv('battery_feature_extracted.csv')\n",
    "X = dataset.drop(columns=['average_voltage'])\n",
    "y = dataset['average_voltage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8f68ab0-172d-4854-8976-fa823469c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/val/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c060e877-c7a8-41dd-aa80-117fe94c9535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5416e53-2576-46c8-8231-57c7a70989b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values).unsqueeze(1)\n",
    "X_val_tensor = torch.FloatTensor(X_val_scaled)\n",
    "y_val_tensor = torch.FloatTensor(y_val.values).unsqueeze(1)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d0e413b-7446-45e9-9f3a-d400d46b90c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample weights\n",
    "ion_columns = [col for col in X.columns if col.startswith(\"working_ion_\")]\n",
    "ion_counts = X_train[ion_columns].sum()\n",
    "ion_weights = 1.0 / ion_counts\n",
    "ion_weights /= ion_weights.sum()\n",
    "train_weights = X_train[ion_columns].dot(ion_weights.astype(np.float32))\n",
    "train_weights_tensor = torch.tensor(train_weights.values.astype(np.float32)).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b690bd9-6763-41fa-9c9d-72a9f6008373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class GRUNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, h_n = self.gru(x)\n",
    "        return self.fc(h_n[-1])\n",
    "\n",
    "class TabTransformerWithGRU(nn.Module):\n",
    "    def __init__(self, num_features, output_size=1, dim_embedding=128, num_heads=2, num_layers=2, gru_hidden_size=128, gru_num_layers=1, gru_dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(num_features, dim_embedding)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=dim_embedding, nhead=num_heads, dropout=0.2, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.gru_network = GRUNetwork(dim_embedding, gru_hidden_size, output_size, gru_num_layers, gru_dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).unsqueeze(1)\n",
    "        x = self.transformer(x)\n",
    "        return self.gru_network(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c37e16ad-6365-4c4e-bae6-ba35e28b6081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "class WeightedCompositeLoss(nn.Module):\n",
    "    def forward(self, outputs, targets, weights):\n",
    "        mse = (weights * (outputs - targets) ** 2).mean()\n",
    "        mae = (weights * torch.abs(outputs - targets)).mean()\n",
    "        return mse + 0.6 * mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d274539-b65a-4626-9d5a-83223cac2cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TabTransformerWithGRU(num_features=X_train_tensor.shape[1]).to(device)\n",
    "criterion = WeightedCompositeLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00075)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4693c09-8d44-47d4-9b5a-af271e352d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move tensors\n",
    "X_train_tensor = X_train_tensor.to(device)\n",
    "y_train_tensor = y_train_tensor.to(device)\n",
    "train_weights_tensor = train_weights_tensor.to(device)\n",
    "X_val_tensor = X_val_tensor.to(device)\n",
    "y_val_tensor = y_val_tensor.to(device)\n",
    "X_test_tensor = X_test_tensor.to(device)\n",
    "y_test_tensor = y_test_tensor.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0c49727a-5a14-45a9-a859-4e9029a607ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train Loss: 0.2747 | Val Loss: 8.0351\n",
      "Epoch 200 | Train Loss: 0.0116 | Val Loss: 1.0323\n",
      "Epoch 400 | Train Loss: 0.0088 | Val Loss: 0.8077\n",
      "Epoch 600 | Train Loss: 0.0078 | Val Loss: 0.7261\n",
      "Epoch 800 | Train Loss: 0.0060 | Val Loss: 0.6960\n",
      "Epoch 1000 | Train Loss: 0.0053 | Val Loss: 0.6796\n",
      "Epoch 1200 | Train Loss: 0.0047 | Val Loss: 0.6560\n",
      "Epoch 1400 | Train Loss: 0.0042 | Val Loss: 0.6597\n",
      "Epoch 1600 | Train Loss: 0.0036 | Val Loss: 0.6556\n",
      "Epoch 1800 | Train Loss: 0.0035 | Val Loss: 0.6387\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "training_losses, validation_losses = [], []\n",
    "for epoch in range(2000):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor, train_weights_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        val_loss = criterion(val_outputs, y_val_tensor, torch.ones_like(y_val_tensor))\n",
    "\n",
    "    training_losses.append(loss.item())\n",
    "    validation_losses.append(val_loss.item())\n",
    "    if epoch % 200 == 0:\n",
    "        print(f\"Epoch {epoch} | Train Loss: {loss.item():.4f} | Val Loss: {val_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "87d8b93f-2190-465b-b16c-5fc6756dab44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test MSE: 0.5510\n",
      "Test MAE: 0.3703\n",
      "Test R²: 0.7897\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(X_test_tensor)\n",
    "    test_mse = mean_squared_error(y_test_tensor.cpu(), preds.cpu())\n",
    "    test_mae = mean_absolute_error(y_test_tensor.cpu(), preds.cpu())\n",
    "    ss_res = torch.sum((y_test_tensor - preds) ** 2)\n",
    "    ss_tot = torch.sum((y_test_tensor - torch.mean(y_test_tensor)) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "\n",
    "print(f\"\\nTest MSE: {test_mse:.4f}\")\n",
    "print(f\"Test MAE: {test_mae:.4f}\")\n",
    "print(f\"Test R²: {r2.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d095285e-bdd8-4b55-b2bc-393c1169d0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-ion metrics on test set (weighted sample):\n",
      "Al: MAE = 0.3120, MSE = 0.1532, R² = 0.8668\n",
      "Ca: MAE = 0.2706, MSE = 0.1560, R² = 0.8737\n",
      "Cs: MAE = 0.7058, MSE = 0.7185, R² = -0.8962\n",
      "K: MAE = 0.2122, MSE = 0.0643, R² = 0.9808\n",
      "Li: MAE = 0.3874, MSE = 0.6845, R² = 0.6776\n",
      "Mg: MAE = 0.5012, MSE = 1.1019, R² = 0.6874\n",
      "Na: MAE = 0.3072, MSE = 0.1899, R² = 0.9052\n",
      "Rb: MAE = 0.2933, MSE = 0.1159, R² = 0.9282\n",
      "Y: MAE = 0.1726, MSE = 0.0338, R² = 0.9280\n",
      "Zn: MAE = 0.3614, MSE = 0.2760, R² = 0.6912\n"
     ]
    }
   ],
   "source": [
    "# Add per-ion metrics\n",
    "X_test_df = X_test.reset_index(drop=True).copy()\n",
    "X_test_df['true'] = y_test.values\n",
    "X_test_df['pred'] = preds.cpu().numpy().flatten()\n",
    "\n",
    "print(\"\\nPer-ion metrics on test set (weighted sample):\")\n",
    "for ion in ion_columns:\n",
    "    subset = X_test_df[X_test_df[ion] == 1]\n",
    "    if not subset.empty:\n",
    "        y_true = subset['true'].values\n",
    "        y_pred = subset['pred'].values\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        print(f\"{ion.replace('working_ion_', '')}: MAE = {mae:.4f}, MSE = {mse:.4f}, R² = {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0121f5a6-29d2-4efa-972c-bd717ab48636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314a8209-756e-41e3-80f7-86f0b9795ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79ebc66-cbe9-4dfe-8119-64c5babc754a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
