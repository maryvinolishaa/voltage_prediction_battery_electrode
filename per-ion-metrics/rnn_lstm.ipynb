{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a87ea259-5f33-4850-bbb8-a1cc135dad82",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7556b2db-0b0b-4a60-8d12-55ae87bcf0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import MSELoss\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf16ada-b35c-4970-9f6c-8ed24d2ac36a",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e82d7b7b-0bdb-4db9-b8f2-aa86b1c68488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv('battery_feature_extracted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc27e09b-51a6-45e7-a04d-a680bd1d8de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target\n",
    "X = dataset.drop(columns=['average_voltage'])\n",
    "y = dataset['average_voltage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3eb5919-01b4-4a4f-964e-b973654006f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split to separate out the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afc3c3f9-31af-495d-b062-f16d14f64b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second split: separate the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)  # 20% for validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c0a4653-44f3-4aca-8e0b-1ff40539b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the features (fit on X_train, apply to all)\n",
    "scaler = RobustScaler()\n",
    "#scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5b7cb63-3a37-4eb7-9ed1-5b945c419148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values).unsqueeze(1)  # Ensure target tensor is of the right shape\n",
    "X_val_tensor = torch.FloatTensor(X_val_scaled)\n",
    "y_val_tensor = torch.FloatTensor(y_val.values).unsqueeze(1)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17449a1c-d0d6-498d-b9da-c1289e214993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "num_features = X_train_scaled.shape[1]\n",
    "output_size = 1  # For regression, we predict a single continuous value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef707475-69e3-4607-863d-4e763e3e4074",
   "metadata": {},
   "source": [
    "# Define and Load the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9e78b9b-1e0c-4643-a77f-531984acbbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf996943-cece-4f83-b8ed-8b2d26034f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM subnetwork\n",
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout=0.5):\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        h_n = h_n[-1]\n",
    "        x = self.fc(h_n)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b53df10b-4a2b-4b4b-a4eb-7104d304d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TabTransformer with LSTM\n",
    "class TabTransformerWithLSTM(nn.Module):\n",
    "    def __init__(self, num_features, output_size=1, dim_embedding=128, num_heads=2, num_layers=2, lstm_hidden_size=128, lstm_num_layers=1, lstm_dropout=0.5):\n",
    "        super(TabTransformerWithLSTM, self).__init__()\n",
    "        self.embedding = nn.Linear(num_features, dim_embedding)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=dim_embedding, nhead=num_heads, batch_first=True, dropout=0.7)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.lstm_network = LSTMNetwork(dim_embedding, lstm_hidden_size, output_size, num_layers=lstm_num_layers, dropout=lstm_dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.transformer(x)\n",
    "        return self.lstm_network(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e6ad73f-967c-4406-bfb1-4c34ece957f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15264\\3680898124.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('entire_model_transformer_rnn_lstm_mae2747_mse2588_r29012.pth', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TabTransformerWithLSTM(\n",
       "  (embedding): Linear(in_features=3226, out_features=128, bias=True)\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.7, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.7, inplace=False)\n",
       "        (dropout2): Dropout(p=0.7, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lstm_network): LSTMNetwork(\n",
       "    (lstm): LSTM(128, 128, batch_first=True, dropout=0.5)\n",
       "    (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model = TabTransformerWithLSTM(num_features=X_train.shape[1]).to(device)\n",
    "model.load_state_dict(torch.load('entire_model_transformer_rnn_lstm_mae2747_mse2588_r29012.pth', map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31e8797e-1b02-403d-9347-a099bcfb139f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabTransformerWithLSTM(\n",
       "  (embedding): Linear(in_features=3226, out_features=128, bias=True)\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.7, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.7, inplace=False)\n",
       "        (dropout2): Dropout(p=0.7, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lstm_network): LSTMNetwork(\n",
       "    (lstm): LSTM(128, 128, batch_first=True, dropout=0.5)\n",
       "    (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af85ca0e-9b9f-4f3b-bc95-59280bfcc338",
   "metadata": {},
   "source": [
    "# Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b8b069f-d840-47c4-8c60-54736b4d2b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.2588\n",
      "Test MAE: 0.2747\n",
      "Test R¬≤:  0.9012\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor.to(device))\n",
    "\n",
    "# Convert predictions and targets to NumPy arrays\n",
    "y_pred = predictions.cpu().numpy().flatten()\n",
    "y_true = y_test_tensor.numpy().flatten()\n",
    "\n",
    "# Compute metrics\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Test MSE: {mse:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")\n",
    "print(f\"Test R¬≤:  {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5155623-2c31-4383-b441-5a914018d858",
   "metadata": {},
   "source": [
    "# per ion metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c243c721-cbd2-4c1c-a120-088bf85eb29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Per-ion metrics on test set:\n",
      "AL      : MAE = 0.2656, MSE = 0.2138, R¬≤ = 0.8141\n",
      "CA      : MAE = 0.2178, MSE = 0.1016, R¬≤ = 0.9178\n",
      "CS      : MAE = 0.3500, MSE = 0.1825, R¬≤ = 0.5184\n",
      "K       : MAE = 0.1500, MSE = 0.0399, R¬≤ = 0.9881\n",
      "LI      : MAE = 0.2767, MSE = 0.2500, R¬≤ = 0.8822\n",
      "MG      : MAE = 0.4108, MSE = 0.7564, R¬≤ = 0.7854\n",
      "NA      : MAE = 0.1938, MSE = 0.0903, R¬≤ = 0.9549\n",
      "RB      : MAE = 0.3254, MSE = 0.1598, R¬≤ = 0.9010\n",
      "Y       : MAE = 0.3649, MSE = 0.2077, R¬≤ = 0.5576\n",
      "ZN      : MAE = 0.2418, MSE = 0.1449, R¬≤ = 0.8379\n"
     ]
    }
   ],
   "source": [
    "# 1. Identify the one-hot encoded ion columns (adjust prefix if needed)\n",
    "ion_columns = [col for col in X_test.columns if col.startswith('working_ion_')]\n",
    "\n",
    "# 2. Create a DataFrame with true/pred values\n",
    "X_test_df = X_test.reset_index(drop=True).copy()\n",
    "X_test_df['true'] = y_true\n",
    "X_test_df['pred'] = y_pred\n",
    "\n",
    "# 3. Compute per-ion metrics\n",
    "print(\"\\nüîç Per-ion metrics on test set:\")\n",
    "for ion in ion_columns:\n",
    "    subset = X_test_df[X_test_df[ion] == 1]\n",
    "    if not subset.empty:\n",
    "        y_true_ion = subset['true'].values\n",
    "        y_pred_ion = subset['pred'].values\n",
    "        mae_ion = mean_absolute_error(y_true_ion, y_pred_ion)\n",
    "        mse_ion = mean_squared_error(y_true_ion, y_pred_ion)\n",
    "        r2_ion = r2_score(y_true_ion, y_pred_ion)\n",
    "        print(f\"{ion.replace('working_ion_', '').upper():<8}: MAE = {mae_ion:.4f}, MSE = {mse_ion:.4f}, R¬≤ = {r2_ion:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
