{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a87ea259-5f33-4850-bbb8-a1cc135dad82",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7556b2db-0b0b-4a60-8d12-55ae87bcf0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import MSELoss\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf16ada-b35c-4970-9f6c-8ed24d2ac36a",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e82d7b7b-0bdb-4db9-b8f2-aa86b1c68488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv('battery_feature_extracted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc27e09b-51a6-45e7-a04d-a680bd1d8de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target\n",
    "X = dataset.drop(columns=['average_voltage'])\n",
    "y = dataset['average_voltage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3eb5919-01b4-4a4f-964e-b973654006f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split to separate out the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afc3c3f9-31af-495d-b062-f16d14f64b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second split: separate the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)  # 20% for validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c0a4653-44f3-4aca-8e0b-1ff40539b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the features (fit on X_train, apply to all)\n",
    "scaler = RobustScaler()\n",
    "#scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5b7cb63-3a37-4eb7-9ed1-5b945c419148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values).unsqueeze(1)  # Ensure target tensor is of the right shape\n",
    "X_val_tensor = torch.FloatTensor(X_val_scaled)\n",
    "y_val_tensor = torch.FloatTensor(y_val.values).unsqueeze(1)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17449a1c-d0d6-498d-b9da-c1289e214993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "num_features = X_train_scaled.shape[1]\n",
    "output_size = 1  # For regression, we predict a single continuous value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef707475-69e3-4607-863d-4e763e3e4074",
   "metadata": {},
   "source": [
    "# Define and Load the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9e78b9b-1e0c-4643-a77f-531984acbbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf996943-cece-4f83-b8ed-8b2d26034f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "        self.residual = nn.Linear(input_size, output_size)  # Residual connection\n",
    "        self.alpha = nn.Parameter(torch.tensor(0.5))  # Learnable weight for residual\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.residual(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer2(x)\n",
    "        return self.alpha * x + (1 - self.alpha) * residual  # Weighted combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b53df10b-4a2b-4b4b-a4eb-7104d304d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the TabTransformer model with FFNN\n",
    "class TabTransformer(nn.Module):\n",
    "    def __init__(self, num_features, output_size=1, dim_embedding=64, num_heads=4, num_layers=4, ffnn_hidden_size=128):\n",
    "        super(TabTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(num_features, dim_embedding)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=dim_embedding, nhead=num_heads, batch_first=True, dropout=0.70)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Replace the regression layer with a custom feed-forward neural network\n",
    "        self.ffnn = FeedForwardNN(dim_embedding, ffnn_hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.unsqueeze(1)  # Adding a sequence dimension\n",
    "        x = self.transformer(x)\n",
    "        x = x[:, 0, :]  # Select the first token (or the entire sequence can be aggregated differently)\n",
    "        x = self.ffnn(x)  # Pass through the feed-forward network\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e6ad73f-967c-4406-bfb1-4c34ece957f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss, and optimizer\n",
    "model = TabTransformer(\n",
    "    num_features=num_features,  # Input feature size\n",
    "    output_size=output_size,   # Output size (1 for regression)\n",
    "    dim_embedding=128,         # Embedding dimension\n",
    "    num_heads=2,               # Number of attention heads\n",
    "    num_layers=2,              # Number of transformer layers\n",
    "    ffnn_hidden_size=128       # Hidden size for the feed-forward neural network\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "349b5515-98f6-4d45-97a5-136d4dc4687d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14396\\4137458595.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('entire_model_transformer_fnn_mae2886_mse2855_r28910.pth', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained weights\n",
    "model.load_state_dict(torch.load('entire_model_transformer_fnn_mae2886_mse2855_r28910.pth', map_location=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31e8797e-1b02-403d-9347-a099bcfb139f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabTransformer(\n",
       "  (embedding): Linear(in_features=3226, out_features=128, bias=True)\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.7, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.7, inplace=False)\n",
       "        (dropout2): Dropout(p=0.7, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ffnn): FeedForwardNN(\n",
       "    (layer1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (activation): ReLU()\n",
       "    (layer2): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (residual): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af85ca0e-9b9f-4f3b-bc95-59280bfcc338",
   "metadata": {},
   "source": [
    "# Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b8b069f-d840-47c4-8c60-54736b4d2b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.2856\n",
      "Test MAE: 0.2887\n",
      "Test R¬≤:  0.8910\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor.to(device))\n",
    "\n",
    "# Convert predictions and targets to NumPy arrays\n",
    "y_pred = predictions.cpu().numpy().flatten()\n",
    "y_true = y_test_tensor.numpy().flatten()\n",
    "\n",
    "# Compute metrics\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Test MSE: {mse:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")\n",
    "print(f\"Test R¬≤:  {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55914d35-b324-4b9e-b26d-5279383e1872",
   "metadata": {},
   "source": [
    "# Per ion metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dec59c66-50f8-4c49-9e77-18b934e491fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Per-ion metrics on test set:\n",
      "AL      : MAE = 0.2139, MSE = 0.1560, R¬≤ = 0.8643\n",
      "CA      : MAE = 0.2162, MSE = 0.1163, R¬≤ = 0.9059\n",
      "CS      : MAE = 0.6300, MSE = 0.6243, R¬≤ = -0.6476\n",
      "K       : MAE = 0.1505, MSE = 0.0417, R¬≤ = 0.9876\n",
      "LI      : MAE = 0.2975, MSE = 0.2826, R¬≤ = 0.8669\n",
      "MG      : MAE = 0.3996, MSE = 0.7394, R¬≤ = 0.7902\n",
      "NA      : MAE = 0.1735, MSE = 0.0655, R¬≤ = 0.9673\n",
      "RB      : MAE = 0.3502, MSE = 0.3169, R¬≤ = 0.8036\n",
      "Y       : MAE = 0.2433, MSE = 0.1224, R¬≤ = 0.7393\n",
      "ZN      : MAE = 0.3107, MSE = 0.2320, R¬≤ = 0.7404\n"
     ]
    }
   ],
   "source": [
    "# 1. Identify the one-hot encoded ion columns (adjust prefix if needed)\n",
    "ion_columns = [col for col in X_test.columns if col.startswith('working_ion_')]\n",
    "\n",
    "# 2. Create a DataFrame with true/pred values\n",
    "X_test_df = X_test.reset_index(drop=True).copy()\n",
    "X_test_df['true'] = y_true\n",
    "X_test_df['pred'] = y_pred\n",
    "\n",
    "# 3. Compute per-ion metrics\n",
    "print(\"\\nüîç Per-ion metrics on test set:\")\n",
    "for ion in ion_columns:\n",
    "    subset = X_test_df[X_test_df[ion] == 1]\n",
    "    if not subset.empty:\n",
    "        y_true_ion = subset['true'].values\n",
    "        y_pred_ion = subset['pred'].values\n",
    "        mae_ion = mean_absolute_error(y_true_ion, y_pred_ion)\n",
    "        mse_ion = mean_squared_error(y_true_ion, y_pred_ion)\n",
    "        r2_ion = r2_score(y_true_ion, y_pred_ion)\n",
    "        print(f\"{ion.replace('working_ion_', '').upper():<8}: MAE = {mae_ion:.4f}, MSE = {mse_ion:.4f}, R¬≤ = {r2_ion:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
